{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewm2jFpzOjH2"
      },
      "source": [
        "Created on Sat Dec  9 19:24:25 2023\n",
        "@author: Michelle Fribance\n",
        "\n",
        "The purpose of this script is to train a Markov Chain model on the combined\n",
        "fortunes dataset, using the markovify library: https://github.com/jsvine/markovify\n",
        "then generate a set of unique fortunes.\n",
        "\n",
        "markovify isn't available through Anaconda; must install using pip on your desired env:\n",
        "pip install markovify\n",
        "\n",
        "Key parameters of the markovify library:\n",
        "state_size (default=2):\n",
        "    - Determines the number of words that form the state of the Markov Chain.\n",
        "    - Larger values generally lead to more coherent but less diverse text.\n",
        "\n",
        "chain (default=None):\n",
        "    - If you have a pre-built chain (possibly from a previous run), you can\n",
        "      provide it to the model using this parameter.\n",
        "   eg:\n",
        "      chain = markovify.Chain.from_text(\" \".join(proverbs), state_size=2)\n",
        "      text_model = markovify.Text(\"\", chain=chain)\n",
        "\n",
        "max_overlap_ratio (default=0.7):\n",
        "    - This parameter controls the maximum allowed ratio of overlapping words\n",
        "      between the sentences.\n",
        "\n",
        "max_overlap_total (default=15):\n",
        "    - This parameter controls the maximum allowed total number of overlapping\n",
        "      words between the sentences.\n",
        "\n",
        "output_max_words (default=200):\n",
        "    - Maximum number of words in the generated sentence.\n",
        "\n",
        "tries (default=10):\n",
        "    - The number of attempts to make a sentence before failing and retrying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d31nXg2lOQh8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import markovify\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.lm import MLE\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Check if punkt is already downloaded\n",
        "try:\n",
        "    # Check if punkt is found\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    # If not found, download punkt\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# Check if wordnet is already downloaded\n",
        "try:\n",
        "    # Check if punkt is found\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    # If not found, download punkt\n",
        "    nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_btxHSRAOnn8"
      },
      "outputs": [],
      "source": [
        "# ------------------- Set variable values and model parameters ------------------ #\n",
        "num_fortunes_to_generate = 100\n",
        "tries = 100\n",
        "\n",
        "# Set hyperparameter values:\n",
        "state_size_values = [2, 3]  # 4 is too slow. Can't generate enough unique fortunes so loops forever\n",
        "max_words_values = [15, 18]\n",
        "max_overlap_ratio_values = [0.5, 0.7, 0.9]\n",
        "cosine_similarity_threshold_values = [0.5, 0.7]\n",
        "cosine_sim_values = [\"true\", \"false\"]        # filter dissimilar generated fortunes?\n",
        "\n",
        "# Set a seed value for reproducibility\n",
        "seed_value = 42\n",
        "random.seed(seed_value)  # Sets the seed for the Python random number generator\n",
        "\n",
        "# Set the display.max_colwidth option to None to show full text in a column\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Create an empty DataFrame to store the optimization results\n",
        "hyperparameter_results_df = pd.DataFrame(columns=[\"State_Size\", \"Max_Words\", \"Max_Overlap_Ratio\", \"Cosine_Similarity_Threshold\", \"Cosine_Similarity\", \"Average_Perplexity\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmdVjnKEPA5N"
      },
      "outputs": [],
      "source": [
        "############################ Function definitions #############################\n",
        "\n",
        "def filter_fortunes_with_cosine_similarity(df_generated_fortunes, train_fortunes):\n",
        "    \"\"\" Removes fortunes with too-low similarity to the training set. For word\n",
        "        embeddings using spaCy, we use the pre-trained spaCy model\n",
        "        \"en_core_web_md\" (medium-sized English model). This model includes word vectors,\n",
        "        and it should work well for general-purpose applications, including fortunes.\"\"\"\n",
        "\n",
        "    # Load the model:\n",
        "    try:\n",
        "        nlp = spacy.load(\"en_core_web_md\")\n",
        "    except OSError:\n",
        "        print(\"Downloading 'en_core_web_md' model...\")\n",
        "        spacy.cli.download(\"en_core_web_md\")\n",
        "        nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "    # Tokenize the training fortunes:\n",
        "    training_tokens = [nlp(fortune) for fortune in train_fortunes]\n",
        "\n",
        "    # Calculate the average vector of all training fortunes:\n",
        "    average_training_vector = np.mean([token.vector for tokens in training_tokens for token in tokens],\n",
        "                                      axis=0)\n",
        "\n",
        "    # Function to calculate cosine similarity with the average training vector:\n",
        "    def calculate_cosine_similarity_with_average(text):\n",
        "        if text is None:\n",
        "            return 0.0\n",
        "        tokens = nlp(text)\n",
        "        vector = np.mean([token.vector for token in tokens], axis=0)\n",
        "        similarity = cosine_similarity([average_training_vector], [vector])[0][0]\n",
        "        return similarity\n",
        "\n",
        "    # Apply the cosine similarity function while handling None values\n",
        "    df_generated_fortunes[\"Passes_Threshold\"] = df_generated_fortunes[\"Generated fortunes\"].apply(\n",
        "        lambda x: calculate_cosine_similarity_with_average(x) if x is not None else 0.0)\n",
        "\n",
        "    # Filter out rows with None values in the \"Generated fortunes\" column\n",
        "    df_generated_fortunes = df_generated_fortunes.dropna(subset=[\"Generated fortunes\"])\n",
        "\n",
        "    cosine_similarity_threshold = 0.7\n",
        "    df_generated_fortunes = df_generated_fortunes.copy()\n",
        "    df_generated_fortunes.loc[:, \"Passes_Threshold\"] = (df_generated_fortunes[\"Passes_Threshold\"] >= cosine_similarity_threshold)\n",
        "\n",
        "    # Filter out generated fortunes below the threshold:\n",
        "    filtered_fortunes = df_generated_fortunes[df_generated_fortunes[\"Passes_Threshold\"]]\n",
        "\n",
        "    # Drop the temporary column\n",
        "    filtered_fortunes = filtered_fortunes.drop(columns=[\"Passes_Threshold\"])\n",
        "\n",
        "    return filtered_fortunes\n",
        "\n",
        "\n",
        "def evaluate_fortune_perplexity(input_fortunes_df, training_fortunes_list):\n",
        "    # Evaluate by calculating perplexity for each fortune\n",
        "\n",
        "    # https://www.nltk.org/api/nltk.lm.html\n",
        "\n",
        "    nlp = spacy.load(\"en_core_web_md\")  # Load pre-trained spaCy model with word vectors\n",
        "\n",
        "    # Tokenize training fortunes and pad with special characters at each sequence's start & end\n",
        "    train_data = [nlp(sentence) for sentence in training_fortunes_list]\n",
        "    vocabulary = [token.text for tokens in train_data for token in tokens]\n",
        "\n",
        "    # Create an NLTK model for the reference data:\n",
        "    n = 2\n",
        "    nltk_model = MLE(n)\n",
        "\n",
        "    # Convert training data into n-grams\n",
        "    train_ngrams = list(nltk.everygrams(vocabulary, max_len=n))\n",
        "\n",
        "    # Fit the model\n",
        "    nltk_model.fit([train_ngrams], vocabulary_text=vocabulary)\n",
        "\n",
        "    # Define a function to calculate perplexity for a given sentence using the trained NLTK model:\n",
        "    def calculate_perplexity(sentence, model, n):\n",
        "        if sentence is None:\n",
        "            return float('inf')  # Return infinity for None values\n",
        "        tokens = nlp(sentence)\n",
        "        ngrams = list(nltk.everygrams(tuple([token.text for token in tokens]), max_len=n))\n",
        "        return model.perplexity(ngrams)\n",
        "\n",
        "    # Add a new column to the DataFrame to store perplexity values\n",
        "    input_fortunes_df[\"perplexity\"] = input_fortunes_df[\"Generated fortunes\"].apply(\n",
        "        lambda x: calculate_perplexity(x, nltk_model, n))\n",
        "\n",
        "    print(input_fortunes_df[[\"Generated fortunes\", \"perplexity\"]])\n",
        "\n",
        "    # Count number of fortunes with \"inf\" perplexity:\n",
        "    inf_perplexity_count = len(input_fortunes_df[input_fortunes_df[\"perplexity\"] == float('inf')])\n",
        "\n",
        "    # Filter out rows with \"inf\" perplexity:\n",
        "    valid_perplexity_df = input_fortunes_df[input_fortunes_df[\"perplexity\"] != float('inf')]\n",
        "\n",
        "    return valid_perplexity_df, inf_perplexity_count\n",
        "\n",
        "######################## End of Function Definitions ##########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZnwxQ0kPLt_"
      },
      "outputs": [],
      "source": [
        "# -------------------------------- Load data -------------------------------- #\n",
        "\n",
        "# Open the original combined_fortunes dataset\n",
        "training_fortunes_path = os.path.join('..', 'datasets', 'combined_fortunes-4632.csv')\n",
        "\n",
        "# TODO What is dataset_path ?\n",
        "with open(dataset_path, 'r') as file:\n",
        "    fortunes = file.readlines()\n",
        "\n",
        "train_fortunes = fortunes\n",
        "\n",
        "# Define a start time to time how long the optimization takes\n",
        "start_time = time.time()\n",
        "\n",
        "number_of_runs = (len(state_size_values) *\n",
        "                  len(max_words_values) *\n",
        "                  len(max_overlap_ratio_values) *\n",
        "                  len(cosine_similarity_threshold_values) *\n",
        "                  len(cosine_sim_values))\n",
        "\n",
        "print(f\"Starting hyperparameter optimization using perplexity as evaluation metric on {number_of_runs} combinations...\")\n",
        "i = 1\n",
        "# Loop through each combination of hyperparameters\n",
        "for state_size in state_size_values:\n",
        "    for max_words in max_words_values:\n",
        "        for max_overlap_ratio in max_overlap_ratio_values:\n",
        "            for cosine_similarity_threshold in cosine_similarity_threshold_values:\n",
        "                for cosine_sim in cosine_sim_values:\n",
        "                    print(f\"Run {i} of {number_of_runs}:\")\n",
        "                    print(\"\\nHyperparameter values:\")\n",
        "                    print(f\"State_Size: {state_size}, Max_Words: {max_words}, Max_Overlap_Ratio: {max_overlap_ratio}\")\n",
        "                    print(f\"Cosine_Similarity_Threshold: {cosine_similarity_threshold}, Cosine_Similarity: {cosine_sim}\\n\")\n",
        "                    # Build the Markov Chain model\n",
        "                    text_model = markovify.Text(\" \".join(train_fortunes), state_size=state_size)\n",
        "\n",
        "                    # Generate a set of fortunes and save to a DataFrame\n",
        "                    df_generated_fortunes = None\n",
        "                    generated_fortunes = []\n",
        "                    while len(generated_fortunes) < num_fortunes_to_generate:\n",
        "                        fortune = text_model.make_sentence(max_words=max_words, max_overlap_ratio=max_overlap_ratio, tries=tries)\n",
        "                        if fortune is not None and fortune not in generated_fortunes:\n",
        "                            generated_fortunes.append(fortune)\n",
        "                    df_generated_fortunes = pd.DataFrame({\"Generated fortunes\": generated_fortunes})\n",
        "\n",
        "                    # Check for duplicates and remove\n",
        "                    df_generated_fortunes.drop_duplicates(inplace=True)\n",
        "\n",
        "                    # If there are less than 100 fortunes, generate more until there are 100\n",
        "                    while len(df_generated_fortunes) < num_fortunes_to_generate:\n",
        "                        additional_fortunes = []\n",
        "                        while len(additional_fortunes) < num_fortunes_to_generate - len(df_generated_fortunes):\n",
        "                            fortune = text_model.make_sentence(max_words=max_words, max_overlap_ratio=max_overlap_ratio, tries=tries)\n",
        "                            if fortune is not None and fortune not in df_generated_fortunes[\"Generated fortunes\"].values:\n",
        "                                additional_fortunes.append(fortune)\n",
        "                        df_generated_fortunes = pd.concat([df_generated_fortunes, pd.DataFrame({\"Generated fortunes\": additional_fortunes})], ignore_index=True)\n",
        "                        df_generated_fortunes.drop_duplicates(inplace=True)\n",
        "\n",
        "                    # Filter out fortunes below the threshold\n",
        "                    if cosine_sim == \"true\":\n",
        "                        filtered_fortunes = filter_fortunes_with_cosine_similarity(df_generated_fortunes, train_fortunes)\n",
        "                    else:\n",
        "                        filtered_fortunes = df_generated_fortunes\n",
        "\n",
        "                    # Evaluate generated fortunes by calculating perplexity\n",
        "                    valid_perplexity_df, inf_perplexity_count = evaluate_fortune_perplexity(input_fortunes_df=filtered_fortunes, training_fortunes_list=train_fortunes)\n",
        "\n",
        "                    # Calculate average perplexity value for the entire valid_perplexity_df\n",
        "                    average_perplexity = valid_perplexity_df[\"perplexity\"].mean()\n",
        "\n",
        "                    # Store the hyperparameters and resulting perplexity in a dictionary\n",
        "                    result_dict = {\n",
        "                        \"State_Size\": state_size,\n",
        "                        \"Max_Words\": max_words,\n",
        "                        \"Max_Overlap_Ratio\": max_overlap_ratio,\n",
        "                        \"Cosine_Similarity_Threshold\": cosine_similarity_threshold,\n",
        "                        \"Cosine_Similarity\": cosine_sim,\n",
        "                        \"Average_Perplexity\": average_perplexity,\n",
        "                        \"Inf_Perplexity_Count\": inf_perplexity_count\n",
        "                    }\n",
        "\n",
        "                    # Append the dictionary to the DataFrame\n",
        "                    hyperparameter_results_df = pd.concat([hyperparameter_results_df, pd.DataFrame(result_dict, index=[0])], ignore_index=True)\n",
        "\n",
        "                    i += 1 # Increment the run counter (only relevant for printing which run you're on)\n",
        "\n",
        "# Calculate the script execution time\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Script execution time: {execution_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF1EDtXOPWn0"
      },
      "outputs": [],
      "source": [
        "# ------------------------- Export results to CSV --------------------------- #\n",
        "\n",
        "# Check for or create \"hyperparameter_optimization\" folder, to store results:\n",
        "hyperparameter_optimization_folder = os.path.join(Markov_Chains_folder_path, \"hyperparameter_optimization\")\n",
        "if not os.path.exists(hyperparameter_optimization_folder):\n",
        "    os.makedirs(hyperparameter_optimization_folder)\n",
        "\n",
        "# Export the generated DataFrame to a CSV file:\n",
        "csv_file_path = os.path.join(hyperparameter_optimization_folder,\n",
        "                             \"hyperparameter_optimization_results-perplexity.csv\")\n",
        "hyperparameter_results_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"\\nHyperparameter optimization results exported to: {csv_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij0NFEyJPYof"
      },
      "outputs": [],
      "source": [
        "# ------------------------- Visualize the results ---------------------------- #\n",
        "\n",
        "# Create subplots for each value of cosine similarity\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "# Loop through each value of cosine similarity\n",
        "for idx, cosine_sim in enumerate(cosine_sim_values):\n",
        "    # Create a color map for different state sizes\n",
        "    colors = ['r', 'g', 'b']\n",
        "\n",
        "    # Initialize variables to track lowest perplexity and its coordinates\n",
        "    min_perplexity = float('inf')\n",
        "    min_x, min_y = None, None\n",
        "\n",
        "    # Loop through each hyperparameter\n",
        "    for state_size, color in zip(state_size_values, colors):\n",
        "        for max_words, marker in zip(max_words_values, ['o', 's']):\n",
        "            # Filter results for the current combination of hyperparameters\n",
        "            filtered_results = hyperparameter_results_df[(hyperparameter_results_df['State_Size'] == state_size) &\n",
        "                                                         (hyperparameter_results_df['Max_Words'] == max_words) &\n",
        "                                                         (hyperparameter_results_df['Cosine_Similarity'] == cosine_sim)]\n",
        "\n",
        "            # Plot the perplexity values\n",
        "            axs[idx].plot(filtered_results['Max_Overlap_Ratio'], filtered_results['Average_Perplexity'],\n",
        "                          marker=marker, linestyle='', color=color, label=f\"State Size: {state_size}, Max Words: {max_words}\")\n",
        "\n",
        "            # Find the lowest perplexity value and its coordinates\n",
        "            min_idx = filtered_results['Average_Perplexity'].idxmin()\n",
        "            x_coord = filtered_results.loc[min_idx, 'Max_Overlap_Ratio']\n",
        "            y_coord = filtered_results.loc[min_idx, 'Average_Perplexity']\n",
        "\n",
        "            # Check if this is the lowest perplexity so far\n",
        "            if y_coord < min_perplexity:\n",
        "                min_perplexity = y_coord\n",
        "                min_x, min_y = x_coord, y_coord\n",
        "\n",
        "    # Set y label\n",
        "    axs[idx].set_ylabel('Perplexity')\n",
        "\n",
        "    # Add title\n",
        "    axs[idx].set_title(f'Perplexity vs Hyperparameters (Cosine Similarity: {cosine_sim})')\n",
        "\n",
        "    # Annotate the lowest perplexity marker\n",
        "    if min_x is not None and min_y is not None:\n",
        "        axs[idx].annotate(f'Lowest Perplexity: {min_perplexity:.2f}',\n",
        "                          xy=(min_x, min_y), xytext=(min_x + 0.01, min_y))  # Adjusted xytext parameter\n",
        "\n",
        "# Set x label for the bottom plot\n",
        "axs[-1].set_xlabel('Max Overlap Ratio')\n",
        "\n",
        "# Set x-axis limit\n",
        "axs[-1].set_xlim(0.4, 1.0)\n",
        "\n",
        "# Add legend to the bottom plot\n",
        "axs[-1].legend()\n",
        "\n",
        "# Save the plot as an image file\n",
        "image_file_path = os.path.join(hyperparameter_optimization_folder, \"hyperparameter_results_plot-perplexity.png\")\n",
        "plt.savefig(image_file_path)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
